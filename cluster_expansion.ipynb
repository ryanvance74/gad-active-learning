{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.load('li_N10_k2_reducedm.npy')\n",
    "y = np.load('syntheticEnergies.npy')\n",
    "\n",
    "rand_state = np.random.RandomState(10)\n",
    "basis_ind = np.arange(M.shape[1])\n",
    "reverse_ind = basis_ind[::-1]\n",
    "# rand_state.shuffle(basis_ind)\n",
    "# shuffled_ind = basis_ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# M_scaled = scaler.fit_transform(M)\n",
    "\n",
    "ctrue, _, _, _ = np.linalg.lstsq(M, y, rcond=None)\n",
    "d = 20\n",
    "M = M[:, reverse_ind]\n",
    "M_modeled = M[:,:d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of design matrix M: {M.shape}\")\n",
    "\n",
    "nsims = 15\n",
    "max_samples = 700\n",
    "\n",
    "# Start with enough samples to ensure the matrix is likely full rank\n",
    "nstart = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(samples, overhead_time, probs=None, nstart=50):\n",
    "    if probs is None:\n",
    "        # Uniform probability for random sampling\n",
    "        probs = np.ones_like(samples, dtype=float)\n",
    "\n",
    "    assert probs.size == samples.size\n",
    "\n",
    "    res = {'chat': [], 'errs': [], 'MTMinv_norm':[], 'c_err': [], 'runtime':[]}\n",
    "    T = samples[:nstart]\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    for i in range(samples.size - nstart + 1):\n",
    "        MTM = M_modeled[T, :]\n",
    "        yT = y[T]\n",
    "        \n",
    "        probsi = np.sqrt(probs[:nstart+i] * (nstart+i))\n",
    "        \n",
    "        # Solve the least squares problem on the sampled subset\n",
    "        chat = np.linalg.lstsq(MTM / probsi.reshape(-1, 1), yT / probsi, rcond=None)[0]\n",
    "        \n",
    "        # Calculate error against the full-dataset model's predictions\n",
    "        res['chat'].append(chat)\n",
    "        res['errs'].append(np.linalg.norm(y - M_modeled @ chat))\n",
    "        # res['c_err'].append(np.linalg.norm(ctrue - chat))\n",
    "        try: \n",
    "            Minv = np.linalg.pinv(MTM)\n",
    "            res['MTMinv_norm'].append(norm(Minv,ord=2))\n",
    "\n",
    "        except np.linalg.LinAlgError:\n",
    "            res['MTMinv_norm'].append(np.nan)\n",
    "        \n",
    "        T = samples[:nstart+i+1]\n",
    "        res['runtime'].append(time.perf_counter() - start_time + overhead_time)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_RAND = []\n",
    "print(\"\\nRunning Random Sampling Simulations...\")\n",
    "for j in range(nsims):\n",
    "    start_time = time.perf_counter()\n",
    "    rand_state = np.random.RandomState(42 + j)\n",
    "    samples = np.arange(M_modeled.shape[0])\n",
    "    rand_state.shuffle(samples)\n",
    "    samples = samples[:max_samples]\n",
    "    \n",
    "    uniform_probs_on_samples = np.ones_like(samples, dtype=float) / M_modeled.shape[0]\n",
    "    RESULTS_RAND.append(run_simulation(samples, time.perf_counter() - start_time, uniform_probs_on_samples, nstart=nstart))\n",
    "    print(f\"Finished simulation {j+1}/{nsims}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Leverage Score Sampling Simulations ---\n",
    "start_time = time.perf_counter()\n",
    "Q, _ = np.linalg.qr(M_modeled)\n",
    "leverage_scores = np.linalg.norm(Q, axis=1)**2\n",
    "\n",
    "# Normalize to get sampling probabilities\n",
    "ls_probs = leverage_scores / leverage_scores.sum()\n",
    "\n",
    "RESULTS_LS = []\n",
    "overhead_time = time.perf_counter() - start_time\n",
    "print(\"\\nRunning Leverage Score Sampling Simulations...\")\n",
    "\n",
    "for j in range(nsims):\n",
    "    rand_state = np.random.RandomState(42 + j)\n",
    "    # Sample without replacement using the leverage score probabilities\n",
    "    ls_samples = rand_state.choice(M_modeled.shape[0], max_samples, p=ls_probs, replace=True)\n",
    "    ls_probs_on_samples = ls_probs[ls_samples]\n",
    "    RESULTS_LS.append(run_simulation(ls_samples, overhead_time, ls_probs_on_samples, nstart=nstart))\n",
    "    print(f\"  Finished simulation {j+1}/{nsims}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leverage_scores_bernoulli_trials_simulation(X,y,log_interval):\n",
    "    Q, _ = np.linalg.qr(X)\n",
    "    lev_scores = np.linalg.norm(Q, axis=1)**2\n",
    "\n",
    "    trials_by_count = {n:{'chat': [], 'errs': []} for n in range(nstart, max_samples+1)}\n",
    "    total_trial_slots = len(trials_by_count.keys())\n",
    "    simulation_num = 0\n",
    "\n",
    "    n_target = nstart\n",
    "    alpha = 0.01\n",
    "    while n_target <= max_samples:\n",
    "        while len(trials_by_count[n_target]['errs']) < nsims:\n",
    "            simulation_num += 1\n",
    "            if simulation_num % log_interval == 0:\n",
    "                print(f\" Simulation Run: {simulation_num} Populated Trials out of Total Trial Slots: {n_target-nstart}/{total_trial_slots}\")\n",
    "            \n",
    "            probs = np.clip(lev_scores * alpha, 0, 1)\n",
    "            row_bernoulli_trials = np.random.binomial(1, probs)\n",
    "\n",
    "            n = np.sum(row_bernoulli_trials)\n",
    "            if n < n_target:\n",
    "                alpha *= 1.02\n",
    "                continue\n",
    "            elif n > n_target:\n",
    "                alpha *= 0.98\n",
    "                continue\n",
    "\n",
    "            selected_rows = X[row_bernoulli_trials == 1, :]\n",
    "\n",
    "            selected_rows_probs = probs[row_bernoulli_trials == 1]\n",
    "\n",
    "            y_sampled = y[row_bernoulli_trials]\n",
    "\n",
    "            probsi = np.sqrt(selected_rows_probs * n).reshape(-1,1)\n",
    "\n",
    "\n",
    "            chat = np.linalg.lstsq(selected_rows / probsi, y_sampled / probsi, rcond=None)[0]\n",
    "            \n",
    "            trials_by_count[n]['chat'].append(chat)\n",
    "            trials_by_count[n]['errs'].append(np.linalg.norm(y - M_modeled @ chat))\n",
    "        \n",
    "        n_target += 1\n",
    "            \n",
    "    return trials_by_count\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bernoulli_results(trials_by_count, nstart, max_samples):\n",
    "    results_list = []\n",
    "\n",
    "    num_trials_per_n = max(len(trials_by_count[n]['errs']) for n in range(nstart, max_samples+1))\n",
    "\n",
    "    for trial_idx in range(num_trials_per_n):\n",
    "        trial_dict = {'errs': [], 'chat':[]}\n",
    "\n",
    "        for n in range(nstart, max_samples+1):\n",
    "\n",
    "            for key in trial_dict.keys():\n",
    "                values = trials_by_count[n][key]\n",
    "                if trial_idx < len(values):\n",
    "                    trial_dict[key].append(values[trial_idx])\n",
    "                else:\n",
    "                    trial_dict[key].append(np.nan)\n",
    "\n",
    "        results_list.append(trial_dict)\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_LS_BERNOULLI = leverage_scores_bernoulli_trials_simulation(M_modeled, y, 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bernoulli_errs = [np.mean(RESULTS_LS_BERNOULLI[n]['errs']) / M_modeled.shape[0] for n in range(nstart,max_samples+1)]\n",
    "plt.loglog(np.arange(nstart,max_samples+1), bernoulli_errs)\n",
    "plt.title(\"Leverage Scores Bernoulli Trials\")\n",
    "plt.xlabel(\"Number of Samples\")\n",
    "plt.ylabel(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_LS_BERNOULLI_FORMATTED = convert_bernoulli_results(RESULTS_LS_BERNOULLI, nstart, max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(leverage_scores), np.sum(ls_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "Q_full, _ = np.linalg.qr(M)\n",
    "leverage_scores_full = np.linalg.norm(Q, axis=1)**2\n",
    "\n",
    "# Normalize to get sampling probabilities\n",
    "ls_probs_full = leverage_scores_full / leverage_scores_full.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.loglog(sorted(leverage_scores, reverse=True), label='modeled')\n",
    "plt.loglog(sorted(leverage_scores_full, reverse=True), label='full')\n",
    "plt.legend()\n",
    "plt.title(\"Leverage Scores\")\n",
    "plt.savefig(\"figures/cluster_expansion/leverage_scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimal_design_sub_mod import run_simulation_greedy_sub_mod\n",
    "\n",
    "RESULTS_OD_SUB_MOD_A = [run_simulation_greedy_sub_mod(M_modeled, y, np.arange(d), ctrue[:d], nstart, max_samples, \"A\")[0]]\n",
    "RESULTS_OD_SUB_MOD_V = [run_simulation_greedy_sub_mod(M_modeled, y, np.arange(d), ctrue[:d], nstart, max_samples, \"V\")[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "max_to_plot = max_samples \n",
    "min_to_plot = 5\n",
    "save = True\n",
    "\n",
    "keys = ['errs', 'MTMinv_norm', 'runtime']\n",
    "for key in keys:\n",
    "    if key == 'errs':\n",
    "        ylabel = r\"Error, $\\|\\hat{f}_{\\mathcal{T}} - f\\|_2$\" \n",
    "    # elif key == 'A_norm':\n",
    "    #     ylabel = r\"$\\|A\\|$\"\n",
    "    elif key == 'MTMinv_norm':\n",
    "        ylabel = r\"$\\|M_{\\mathcal{TM}}^\\dagger\\|$\"\n",
    "    elif key == 'c_err':\n",
    "        ylabel = r\"$\\|c - \\hat{c}\\|$\"\n",
    "    elif key == 'runtime':\n",
    "        ylabel = 'Time (s)'\n",
    "\n",
    "    savename = f\"{key.lower()}_cluster_expansion_reversed.png\"\n",
    "    fig, ax = plt.subplots()\n",
    "    for results, name in zip([RESULTS_RAND, RESULTS_LS, RESULTS_OD_SUB_MOD_A, RESULTS_OD_SUB_MOD_V, RESULTS_LS_BERNOULLI_FORMATTED], ['Random', 'Lev_Score', 'OD_Sub_Mod_A', 'OD_Sub_Mod_V', 'LS Bernoulli']):\n",
    "        metric = np.array([res[key] for res in results])\n",
    "        if key == 'errs':\n",
    "            metric /= M_modeled.shape[0]\n",
    "        mean = metric.mean(axis=0)\n",
    "        # std = metric.std(axis=0)\n",
    "        \n",
    "        l = ax.loglog(np.arange(nstart, len(mean) + nstart), mean, label=name, linestyle='-')\n",
    "\n",
    "\n",
    "        # ax.fill_between(np.arange(nstart, len(mean) + nstart), mean, mean + std, color=l[0].get_color(), alpha=0.5 )\n",
    "        # for err in errs:\n",
    "        #     ax.plot(np.arange(nstart, len(mean) + nstart), err, alpha=0.25, color=l[0].get_color())\n",
    "\n",
    "\n",
    "    ax.legend(title='Sampling Method', fontsize=11)\n",
    "    ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "    ax.set_ylabel(ylabel, fontsize=15)\n",
    "\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", linewidth=0.5)\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        outdir = f\"figures/cluster_expansion\"\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        plt.savefig(f\"{outdir}/{savename}\", dpi=250, format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat's over time\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "import os\n",
    "ctrue_observed = ctrue[:d]\n",
    "for results, name in zip([RESULTS_RAND, RESULTS_LS, RESULTS_OD_SUB_MOD_A, RESULTS_OD_SUB_MOD_V], ['Random', 'Lev_score', 'OD_Sub_Mod_A', 'OD_Sub_Mod_V']):\n",
    "    data = np.array(results[0]['chat'])\n",
    "    \n",
    "    n_frames, n_points = data.shape\n",
    "    x = np.arange(n_points)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    line_approx, = ax.plot([], [], lw=2, label=f\"{name} sampling\")\n",
    "    line_ground_truth, = ax.plot([],[],lw=2, label=\"ground truth\")\n",
    "\n",
    "    ax.set_xlim(0, n_points - 1)\n",
    "    ax.set_ylim(-1, 1)\n",
    "    ax.set_title(f\"{name} chat\")\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    def init():\n",
    "        line_approx.set_data([], [])\n",
    "        line_ground_truth.set_data([], [])\n",
    "        return line_approx, line_ground_truth\n",
    "\n",
    "    def update(frame):\n",
    "        line_approx.set_data(x, data[frame])\n",
    "        line_ground_truth.set_data(x, ctrue_observed)\n",
    "        ax.set_title(f\"{name} chat frame {frame+1}/{n_frames}\")\n",
    "        return line_approx, line_ground_truth\n",
    "\n",
    "    ani = FuncAnimation(fig, update, frames=n_frames,\n",
    "                        init_func=init, blit=False, interval=10)\n",
    "\n",
    "    writer = PillowWriter(fps=30)\n",
    "    outdir = f\"figures/cluster_expansion/{name.lower()}\"\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "    ani.save(f\"{outdir}/chat_evolution_{name.lower()}.gif\", writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpy2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
