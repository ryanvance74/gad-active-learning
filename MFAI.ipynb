{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from numpy.linalg import norm as norm \n",
    "from numpy.linalg import pinv\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from numpy.polynomial import chebyshev as cheb\n",
    "# cheb.chebvander.__name__ = \"Chebyshev\"\n",
    "\n",
    "interval = (-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.linspace(-1., 1., 1001)\n",
    "k = 30\n",
    "nk = 2*(k+1)\n",
    "M = cheb.chebvander(X, deg=nk)\n",
    "\n",
    "obs_set = np.arange(k+1)\n",
    "rand_state = np.random.RandomState(10)\n",
    "\n",
    "ctrue = np.zeros(nk+1)\n",
    "ctrue[2*k ] = 1.5\n",
    "# ctrue[2*k+1] = 1.0\n",
    "ctrue[1] = 0.5\n",
    "ctrue += rand_state.randn(ctrue.size)\n",
    "\n",
    "f = M @ ctrue \n",
    "\n",
    "chat_true = np.zeros_like(ctrue)\n",
    "sol = np.linalg.lstsq(M[:,obs_set], f, rcond=None)\n",
    "chat_true[obs_set] = sol[0]\n",
    "\n",
    "inds = np.arange(X.size)\n",
    "rand_state.shuffle(inds)\n",
    "Mprime = M[inds]\n",
    "chat_true2 = np.zeros_like(ctrue)\n",
    "sol2 = np.linalg.lstsq(Mprime[:,obs_set]/X.size, f[inds]/X.size, rcond=None)\n",
    "chat_true2[obs_set] = sol[0]\n",
    "\n",
    "print(np.allclose(chat_true2, chat_true))\n",
    "\n",
    "\n",
    "\n",
    "print(ctrue)\n",
    "print(np.round(chat_true, 2))\n",
    "print(obs_set)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, f, 'k-', label='gt')\n",
    "ax.plot(X, M@chat_true, label='true estimate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nstart = 5\n",
    "basis_idx = np.arange(ctrue.size)\n",
    "\n",
    "\n",
    "def run_simulation(samples, probs=None, nstart=5):\n",
    "    if probs is None:\n",
    "        probs = np.ones_like(samples, dtype=float)\n",
    "\n",
    "    assert probs.size == samples.size\n",
    "\n",
    "    res = {'chat':[], 'errs':[], 'A_norm':[], 'MTMinv_norm':[], 'MTU_norm':[]}\n",
    "    T = samples[:nstart]\n",
    "    U = np.setdiff1d(np.arange(X.size), T) \n",
    "    rs = np.random.RandomState(10)\n",
    "    noise = 0.1*rs.rand(X.size)\n",
    "    \n",
    "\n",
    "    for i in range(samples.size - nstart+1):\n",
    "        MTM = M[np.ix_(T,obs_set)]\n",
    "        MTU = M[np.ix_(T,np.delete(np.arange(M.shape[1]), obs_set))]\n",
    "        probsi = np.sqrt(probs[:nstart+i]*(nstart+i))\n",
    "        #probsi = np.sqrt(probs[:nstart+i])\n",
    "        y = M[T,:] @ ctrue #+ noise[T]\n",
    "        sol = np.linalg.lstsq(MTM/probsi.reshape(-1, 1), y/probsi, rcond=None)\n",
    "        chat = np.zeros_like(ctrue, dtype=float)\n",
    "        chat[obs_set] = sol[0]\n",
    "        res['chat'].append(chat) \n",
    "        res['errs'].append(np.linalg.norm(M@(ctrue - chat)))\n",
    "        \n",
    "        try: \n",
    "            Minv = pinv(MTM)\n",
    "            res['MTMinv_norm'].append(np.log10(norm(Minv)))\n",
    "            res['MTU_norm'].append(np.log10(norm(MTU)))\n",
    "            res['A_norm'].append(np.log10(norm(Minv @ MTU)))\n",
    "\n",
    "        except np.linalg.LinAlgError:\n",
    "            res['MTMinv_norm'].append(np.nan)\n",
    "            res['MTU_norm'].append(np.nan)\n",
    "            res['A_norm'].append(np.nan)\n",
    "\n",
    "        T = samples[:nstart+i+1]\n",
    "        U = np.setdiff1d(np.arange(X.size), T)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return res \n",
    "\n",
    "\n",
    "def run_simulation_nodes(ntotal, nstart=5, method='chebyshev'):\n",
    "    if method == \"chebyshev\":\n",
    "        Tx = cheb.chebpts2(nstart)\n",
    "    elif method == \"lattice\":\n",
    "        Tx = np.linspace(-1,1,nstart) \n",
    "    else:\n",
    "        raise NotImplementedError(f\"method = {method} not recognized...\")\n",
    "\n",
    "    res = {'chat':[], 'errs':[], 'A_norm':[], 'MTMinv_norm':[], 'MTU_norm':[]}\n",
    "    \n",
    "\n",
    "    for i in range(ntotal - nstart):\n",
    "        M_ = cheb.chebvander(Tx, deg=nk)\n",
    "        MTM = M_[:,obs_set]\n",
    "        MTU = M_[:,np.delete(np.arange(M_.shape[1]), obs_set)]\n",
    "        y = M_ @ ctrue\n",
    "        sol = np.linalg.lstsq(MTM, y, rcond=None)\n",
    "        chat = np.zeros_like(ctrue, dtype=float)\n",
    "        chat[obs_set] = sol[0]\n",
    "        res['chat'].append(chat) \n",
    "        res['errs'].append(np.linalg.norm(M@(chat_true - chat)))\n",
    "        \n",
    "        try: \n",
    "            Minv = pinv(MTM)\n",
    "            res['MTMinv_norm'].append(np.log10(norm(Minv)))\n",
    "            res['MTU_norm'].append(np.log10(norm(MTU)))\n",
    "            res['A_norm'].append(np.log10(norm(Minv @ MTU)))\n",
    "\n",
    "        except np.linalg.LinAlgError:\n",
    "            res['MTMinv_norm'].append(np.nan)\n",
    "            res['MTU_norm'].append(np.nan)\n",
    "            res['A_norm'].append(np.nan)\n",
    "        if method == \"chebyshev\":\n",
    "            Tx = cheb.chebpts2(nstart+i+1)\n",
    "        elif method == \"lattice\":\n",
    "            Tx = np.linspace(-1,1,nstart+i+1)\n",
    "    return res \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 1001\n",
    "nsims = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"res_wgt.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"rand\":RESULTS_RAND, \"ls\":RESULTS_LS}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random\n",
    "RESULTS_RAND = []\n",
    "for j in tqdm(range(nsims), total=nsims):\n",
    "    rand_state = np.random.RandomState(45+j)\n",
    "    samples = np.arange(X.size)\n",
    "    rand_state.shuffle(samples)\n",
    "    samples = samples[:max_samples]\n",
    "    RESULTS_RAND.append(run_simulation(samples, nstart=nstart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs, _ = np.linalg.qr(M[:,obs_set])\n",
    "poly_ls_probs_s = np.linalg.norm(Qs, axis=1)**2.\n",
    "print(poly_ls_probs_s.max(), poly_ls_probs_s.min(), poly_ls_probs_s.sum())\n",
    "poly_ls_probs_s /= poly_ls_probs_s.sum()\n",
    "\n",
    "RESULTS_LS = []\n",
    "\n",
    "for j in tqdm(range(nsims), total=nsims):\n",
    "    rand_state = np.random.RandomState(45+j)\n",
    "    poly_ls_samples_s = rand_state.choice(X.size, max_samples, p=poly_ls_probs_s)\n",
    "    poly_ls_probs_s_on_samples = poly_ls_probs_s[poly_ls_samples_s]\n",
    "    RESULTS_LS.append(run_simulation(poly_ls_samples_s, poly_ls_probs_s_on_samples, nstart=nstart))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chebyshev nodes\n",
    "res_cheb = run_simulation_nodes(max_samples, nstart=nstart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattice nodes\n",
    "res_lattice = run_simulation_nodes(max_samples, nstart=nstart, method='lattice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_plot = 1002 #max_samples\n",
    "min_to_plot = obs_set.size-2\n",
    "save = False\n",
    "key = 'errs'\n",
    "if key == 'errs':\n",
    "    ylabel = r\"Error, $\\|\\hat{f}_{\\mathcal{T}} - f\\|_2$\"\n",
    "    \n",
    "elif key == 'A_norm':\n",
    "    ylabel = r\"$\\|A\\|$\"\n",
    "elif key == 'MTMinv_norm':\n",
    "    ylabel = r\"\\|$M_{\\mathcal{TM}}^\\dagger\\|\"\n",
    "else:\n",
    "    raise NotImplementedError(f\"key = {key} not recognized...\")\n",
    "\n",
    "savename = f\"{key.lower()}.png\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for results, name in zip([RESULTS_RAND, RESULTS_LS], ['Random', 'Lev. Score']):\n",
    "    errs = np.array([res[key][min_to_plot-nstart:max_to_plot] for res in results])\n",
    "    errs /= X.size \n",
    "    print(errs.shape)\n",
    "    mean = errs.mean(axis=0)\n",
    "    std = errs.std(axis=0)\n",
    "    line = ax.loglog(np.arange(min_to_plot, len(errs[0]) + min_to_plot), mean, label=name)[0]\n",
    "    # ax.fill_between(np.arange(min_to_plot, len(errs[0])+min_to_plot), mean, mean+std, color=line.get_color(), alpha=0.6)\n",
    "# cheb_errs = np.array(res_cheb[key][min_to_plot-nstart:max_to_plot])/X.size\n",
    "# ax.loglog(np.arange(min_to_plot, len(cheb_errs)+min_to_plot), cheb_errs, '--', label='Cheb. Nodes')\n",
    "# lat_errs = np.array(res_lattice[key][min_to_plot-nstart:max_to_plot])/X.size\n",
    "# ax.loglog(np.arange(min_to_plot, len(lat_errs)+min_to_plot), lat_errs, '--', label='Lattice Nodes')\n",
    "\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(ylabel, fontsize=15)\n",
    "if save:\n",
    "    plt.savefig(savename, dpi=250, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_plot = 700 #max_samples\n",
    "min_to_plot = nstart + 1 # obs_set.size\n",
    "save = True\n",
    "key = 'A_norm'\n",
    "if key == 'err':\n",
    "    ylabel = r\"Error, $\\|\\hat{f}_{\\mathcal{T}} - f\\|_2$\"\n",
    "    \n",
    "elif key == 'A_norm':\n",
    "    ylabel = r\"$\\|A\\|$\"\n",
    "elif key == 'MTMinv_norm':\n",
    "    ylabel = r\"\\|$M_{\\mathcal{TM}}^\\dagger\\|\"\n",
    "else:\n",
    "    raise NotImplementedError(f\"key = {key} not recognized...\")\n",
    "\n",
    "savename = f\"{key.lower()}.png\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for results, name in zip([RESULTS_RAND, RESULTS_LS], ['Random', 'Lev. Score']):\n",
    "    errs = np.array([res[key][min_to_plot-nstart:max_to_plot] for res in results])\n",
    "    errs /= X.size \n",
    "    mean = errs.mean(axis=0)\n",
    "    std = errs.std(axis=0)\n",
    "    line = ax.loglog(np.arange(min_to_plot, len(errs[0]) + min_to_plot), mean, label=name)[0]\n",
    "    #ax.fill_between(np.arange(nstart, len(errs[0])+nstart), np.maximum(mean-std, 1e-2), mean+std, color=line.get_color(), alpha=0.6)\n",
    "# cheb_errs = np.array(res_cheb[key][min_to_plot-nstart:max_to_plot])/X.size\n",
    "# ax.loglog(np.arange(min_to_plot, len(cheb_errs)+min_to_plot), cheb_errs, '--', label='Cheb. Nodes')\n",
    "# lat_errs = np.array(res_lattice[key][min_to_plot-nstart:max_to_plot])/X.size\n",
    "# ax.loglog(np.arange(min_to_plot, len(lat_errs)+min_to_plot), lat_errs, '--', label='Lattice Nodes')\n",
    "\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(ylabel, fontsize=15)\n",
    "if save:\n",
    "    plt.savefig(savename, dpi=250, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_plot = 700 # max_samples\n",
    "min_to_plot = nstart + 1 #obs_set.size\n",
    "save = True\n",
    "key = 'MTMinv_norm'\n",
    "if key == 'err':\n",
    "    ylabel = r\"Error, $\\|\\hat{f}_{\\mathcal{T}} - f\\|_2$\"\n",
    "elif key == 'A_norm':\n",
    "    ylabel = r\"$\\|A\\|$\"\n",
    "elif key == 'MTMinv_norm':\n",
    "    ylabel = r\"$\\|M_{\\mathcal{TM}}^\\dagger\\|$\"\n",
    "else:\n",
    "    raise NotImplementedError(f\"key = {key} not recognized...\")\n",
    "\n",
    "savename = f\"{key.lower()}.png\"\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for results, name in zip([RESULTS_RAND, RESULTS_LS], ['Random', 'Lev. Score']):\n",
    "    errs = np.array([res[key][min_to_plot-nstart:max_to_plot] for res in results])\n",
    "    errs /= X.size \n",
    "    mean = errs.mean(axis=0)\n",
    "    mean[mean < 0] = np.nan\n",
    "    std = errs.std(axis=0)\n",
    "    line = ax.loglog(np.arange(min_to_plot, len(errs[0]) + min_to_plot), mean, label=name)[0]\n",
    "    #ax.fill_between(np.arange(nstart, len(errs[0])+nstart), np.maximum(mean-std, 1e-2), mean+std, color=line.get_color(), alpha=0.6)\n",
    "# cheb_errs = np.array(res_cheb[key][min_to_plot-nstart:max_to_plot])/X.size\n",
    "# cheb_errs[cheb_errs < 0] = np.nan\n",
    "# ax.loglog(np.arange(min_to_plot, len(cheb_errs)+min_to_plot), cheb_errs, '--', label='Cheb. Nodes')\n",
    "# lat_errs = np.array(res_lattice[key][min_to_plot-nstart:max_to_plot])/X.size\n",
    "# lat_errs[lat_errs < 0] = np.nan\n",
    "# ax.loglog(np.arange(min_to_plot, len(lat_errs)+min_to_plot), lat_errs, '--', label='Lattice Nodes')\n",
    "\n",
    "print(cheb_errs.min())\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(ylabel, fontsize=15)\n",
    "if save:\n",
    "    plt.savefig(savename, dpi=250, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(res, samples, savename, do_anim=True):\n",
    "    if do_anim:\n",
    "        ## make gif of the progression of coefficients\n",
    "        niter = len(res['chat'])\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(basis_idx, ctrue, marker='o', s=20, c='k')\n",
    "        color = iter(plt.cm.viridis(np.linspace(0, 1, niter)))\n",
    "        scat = ax.scatter(basis_idx, res['chat'][0], label=0, marker='x')\n",
    "        ax.set_title(\"Iter = 0\")\n",
    "        ax.set_ylim(ctrue.min()-0.5, ctrue.max()+0.5)\n",
    "\n",
    "        def animate(i):\n",
    "            scat.set_offsets(np.hstack((basis_idx.reshape(-1,1), res['chat'][i].reshape(-1,1))))\n",
    "            # scat.set_color(basis_idx.size*[c])\n",
    "            ax.set_title(f\"Iter = {i+1}\")\n",
    "            return scat, \n",
    "\n",
    "        ani = animation.FuncAnimation(fig, animate, repeat=True,\n",
    "                                            frames=len(res['chat']) - 1, interval=50)\n",
    "        # To save the animation using Pillow as a gif\n",
    "        writer = animation.PillowWriter(fps=5,\n",
    "                                        metadata=dict(artist='Me'),\n",
    "                                        bitrate=1800)\n",
    "        ani.save(f'scatter_{savename}.gif', writer=writer)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    ## plot estimated functions\n",
    "    niter = 10\n",
    "    itermax = 20\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(X, f, 'k-', alpha=0.7)\n",
    "    ax.scatter(X[samples[:nstart+itermax]], M[samples[:nstart+itermax]] @ ctrue, marker='o', s=20, c='k')\n",
    "    color = iter(plt.cm.viridis(np.linspace(0, 1, niter)))\n",
    "    for i in range(itermax-niter,itermax):\n",
    "        c = next(color)\n",
    "        Ti = samples[:nstart+i]\n",
    "        Design_mat = M[np.ix_(Ti, obs_set)]\n",
    "        ax.scatter(X[Ti], Design_mat @ res['chat'][i][obs_set], label=i, marker='x', c=Ti.size*[c])\n",
    "        ax.plot(X, M @ res['chat'][i], c=c)\n",
    "\n",
    "    ax.legend(title='Iteration', bbox_to_anchor=(1.2, 1.05))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    if do_anim:\n",
    "        ## make gif of the progression of coefficients\n",
    "        niter = len(res['chat'])\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(X, f, 'k-', alpha=0.7)\n",
    "        ax.plot(X, M@chat_true, 'r-', alpha=0.8)\n",
    "        #ax.scatter(X[T[:nstart]], M[T[:nstart]] @ ctrue, marker='o', s=20, c='k')\n",
    "        Ti = samples[:nstart]\n",
    "        Design_mat = M[np.ix_(Ti, obs_set)]\n",
    "        scat = ax.scatter(X[Ti], Design_mat @ res['chat'][0][obs_set], marker='x')\n",
    "        line = ax.plot(X, M @ res['chat'][0])[0]\n",
    "        ax.set_title(\"Iter = 0\")\n",
    "        ax.set_ylim(f.min()-0.1, f.max()+0.1)\n",
    "\n",
    "        def animate(i):\n",
    "            Ti = samples[:nstart+i]\n",
    "            Design_mat = M[np.ix_(Ti, obs_set)]\n",
    "            yscat = Design_mat @ res['chat'][i][obs_set]\n",
    "            scat.set_offsets(np.hstack((X[Ti].reshape(-1,1), yscat.reshape(-1,1))))\n",
    "            line.set_ydata(M @ res['chat'][i])\n",
    "            ax.set_title(f\"Iter = {i+1}\")\n",
    "            return (scat, line)\n",
    "\n",
    "        ani = animation.FuncAnimation(fig, animate, repeat=True,\n",
    "                                            frames=len(res['chat']) - 1, interval=50)\n",
    "        # To save the animation using Pillow as a gif\n",
    "        writer = animation.PillowWriter(fps=5,\n",
    "                                        metadata=dict(artist='Me'),\n",
    "                                        bitrate=1800)\n",
    "        ani.save(f'plot_{savename}.gif', writer=writer)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q, _ = np.linalg.qr(M)\n",
    "poly_ls_probs = np.linalg.norm(Q, axis=1)**2.\n",
    "print(poly_ls_probs.max(), poly_ls_probs.min(), poly_ls_probs.sum())\n",
    "poly_ls_probs /= poly_ls_probs.sum()\n",
    "\n",
    "rand_state = np.random.RandomState(45)\n",
    "\n",
    "poly_ls_samples = rand_state.choice(X.size, max_samples, p=poly_ls_probs)\n",
    "print(poly_ls_samples.size)\n",
    "poly_ls_probs_on_samples = poly_ls_probs[poly_ls_samples]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(X, poly_ls_probs)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ls_poly = run_simulation(poly_ls_samples, poly_ls_probs_on_samples, nstart=nstart)\n",
    "\n",
    "#plot_results(res_ls_poly, poly_ls_samples, 'ls_poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_results(res_ls_poly, poly_ls_samples, 'ls_poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qs, _ = np.linalg.qr(M[:,obs_set])\n",
    "poly_ls_probs_s = np.linalg.norm(Qs, axis=1)**2.\n",
    "print(poly_ls_probs_s.max(), poly_ls_probs_s.min(), poly_ls_probs_s.sum())\n",
    "poly_ls_probs_s /= poly_ls_probs_s.sum()\n",
    "\n",
    "rand_state = np.random.RandomState(45)\n",
    "\n",
    "poly_ls_samples_s = rand_state.choice(X.size, max_samples, p=poly_ls_probs_s)\n",
    "print(poly_ls_samples_s.size)\n",
    "poly_ls_probs_s_on_samples = poly_ls_probs_s[poly_ls_samples_s]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(X, poly_ls_probs_s)\n",
    "# plt.show()\n",
    "\n",
    "res_ls_poly_s = run_simulation(poly_ls_samples_s, poly_ls_probs_s_on_samples, nstart=nstart)\n",
    "\n",
    "#plot_results(res_ls_poly_s, poly_ls_samples_s, 'ls_poly2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot_results(res_cheb, poly_ls_samples_s, 'ls_poly2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib \n",
    "plt.rcParams.setdefault('font.family')\n",
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    # \"font.family\": \"sans-serif\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_plot = max_samples\n",
    "fig, ax = plt.subplots()\n",
    "for results, name in zip([RESULTS_RAND, RESULTS_LS], ['Random', 'Lev. Score']):\n",
    "    errs = np.array([res['errs'][:max_to_plot] for res in results])\n",
    "    errs /= X.size #(nstart +np.arange(len(errs), dtype=float))\n",
    "    print(errs.shape)\n",
    "    ax.loglog(np.arange(nstart, len(errs[0])+nstart), errs.mean(axis=0), label=name)\n",
    "cheb_errs = res_cheb['errs'][:max_to_plot]\n",
    "ax.loglog(np.arange(nstart, len(cheb_errs)+nstart), cheb_errs, label='Cheb. Nodes')\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(r\"Error, $\\|\\hat{f}_{\\mathcal{T}} - f\\|_2$\", fontsize=15)\n",
    "# plt.savefig(\"ls_vs_rand_poly.png\", dpi=250, format='png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_plot = max_samples\n",
    "fig, ax = plt.subplots()\n",
    "for res, name in zip([res_rand, res_ls_poly_s, res_cheb], ['Random', 'Lev. Score', 'Cheb. Nodes']): \n",
    "    errs = np.array(res['errs'][:max_to_plot])\n",
    "    errs /= X.size #(nstart +np.arange(len(errs), dtype=float))\n",
    "    ax.loglog(np.arange(nstart, len(errs)+nstart), errs, label=name)\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(r\"Error, $\\|\\hat{f}_{\\mathcal{T}} - f\\|_2$\", fontsize=15)\n",
    "plt.savefig(\"ls_vs_rand_poly.png\", dpi=250, format='png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for res, name in zip([res_rand, res_ls_poly_s, res_cheb], ['Random', 'Lev. Score', 'Cheb. Nodes']): \n",
    "    chats = res['chat'][:max_to_plot]\n",
    "    errs = np.array([np.linalg.norm(ctrue - chat) for chat in chats])\n",
    "    ax.loglog(np.arange(nstart, len(errs)+nstart), errs, label=name)\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(r\"Error, $\\|\\hat{\\theta}_{\\mathcal{T}} - \\theta\\|_2$\", fontsize=15)\n",
    "plt.savefig(\"ls_vs_rand_poly_theta.png\", dpi=250, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_cheb['chat'][-1][obs_set])\n",
    "print(chat_true[obs_set])\n",
    "print(res_rand['chat'][-1][obs_set])\n",
    "print(np.allclose(X, X[np.sort(samples)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cheb.chebvander(X, deg=nk)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, f, 'k-', label='gt')\n",
    "ax.plot(X, M@res_cheb['chat'][-1], 'r-', label='cheb')\n",
    "ax.plot(X, M@chat_true, 'g-', label='full')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_to_plot = 400\n",
    "fig, ax = plt.subplots()\n",
    "for res, name in zip([res_rand, res_ls_poly, res_ls_poly_s, res_cheb], ['Random', 'Lev. Score', 'Lev. Score Sub', 'Cheb. Nodes']): \n",
    "    errs = res['A_norm'][:max_to_plot]\n",
    "    errs /= (nstart +np.arange(len(errs), dtype=float))\n",
    "    ax.loglog(np.arange(nstart, len(errs)+nstart), errs, label=name)\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(r\"$\\|A\\|$\", fontsize=15)\n",
    "# plt.savefig(\"ls_vs_rand_poly.png\", dpi=250, format='png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for res, name in zip([res_rand, res_ls_poly, res_ls_poly_s, res_cheb], ['Random', 'Lev. Score', 'Lev. Score Sub', 'Cheb. Nodes']): \n",
    "    errs = res['MTMinv_norm'][:max_to_plot]\n",
    "    errs /= (nstart +np.arange(len(errs), dtype=float))\n",
    "    ax.loglog(np.arange(nstart, len(errs)+nstart), errs, label=name)\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(r\"$\\|M_{\\mathcal{TM}}^\\dagger\\|$\", fontsize=15)\n",
    "# plt.savefig(\"ls_vs_rand_poly.png\", dpi=250, format='png')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for res, name in zip([res_rand, res_ls_poly, res_ls_poly_s, res_cheb], ['Random', 'Lev. Score', 'Lev. Score Sub', 'Cheb. Nodes']): \n",
    "    errs = res['MTU_norm'][:max_to_plot]\n",
    "    errs /= (nstart +np.arange(len(errs), dtype=float))\n",
    "    ax.loglog(np.arange(nstart, len(errs)+nstart), errs, label=name)\n",
    "ax.legend(title='Sampling Method', fontsize=11)\n",
    "ax.set_xlabel(r\"Size of Training Set, $\\mathcal{T}$\", fontsize=15)\n",
    "ax.set_ylabel(r\"$\\|M_{\\mathcal{TU}}\\|$\", fontsize=15)\n",
    "# plt.savefig(\"ls_vs_rand_poly.png\", dpi=250, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X, f, 'k-', label=r'ground truth, $f$')\n",
    "ax.plot(X, M@chat_true, 'g-', label=r'\"full\" estimate, $\\hat{f}$')\n",
    "line = ax.plot(X, M@res_ls_poly['chat'][80], 'r-', label=r'estimate, $\\hat{f}_{\\mathcal{T}}$')[0]\n",
    "#ax.scatter(X[poly_ls_samples[:nstart +20]], f[poly_ls_samples[:nstart +20]], marker='x', c=line.get_color(), zorder=10)\n",
    "ax.legend(fontsize=13)\n",
    "ax.set_xlabel(r'$x$', fontsize=15)\n",
    "ax.set_ylabel(r'$f(x)$', fontsize=15)\n",
    "plt.savefig('gt_vs_full.png', dpi=250, format='png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations\n",
    "\n",
    "Why doesn't this do as well as we would think that leverage score sampling would? Is it because of the basis? Maybe try doing polynomials, and make sure this regression framework code works over there. \n",
    "\n",
    "\n",
    "Ideas:\n",
    "* Higher dimensional example to see the benefit of leverage score sampling?\n",
    "* Investigate how using Chebyshev nodes helps in this setting, does it essentially do like random or leverage score sampling?\n",
    "* Perhaps what's more useful is looking at the norms of the matrices, not the convergence to the \"full estimate\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = cheb.chebpts2(100)\n",
    "print(pts)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pts, np.ones_like(pts))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
